{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Demo 4: FP-Growth and DataStax Analytics\n",
    "------\n",
    "<img src=\"images/pixarMovies.jpg\" width=\"500\" height=\"500\">\n",
    "\n",
    "\n",
    "#### Dataset: https://grouplens.org/datasets/movielens/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What are we trying to learn from this dataset? \n",
    "\n",
    "# QUESTION: Can FP-Growth be used to find which movies to recommend to our users?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas\n",
    "import cassandra\n",
    "import pyspark\n",
    "import re\n",
    "import os\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "from random import randint, randrange\n",
    "from IPython.display import display, Markdown\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.ml.fpm import FPGrowth\n",
    "from pyspark.sql import Row\n",
    "from pyspark.sql.functions import collect_set\n",
    "from pyspark.ml.feature import IndexToString, StringIndexer, VectorAssembler\n",
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Helper for pretty formatting for Spark DataFrames\n",
    "def showDF(df, limitRows =  5, truncate = True):\n",
    "    if(truncate):\n",
    "        pandas.set_option('display.max_colwidth', 50)\n",
    "    else:\n",
    "        pandas.set_option('display.max_colwidth', None)\n",
    "    pandas.set_option('display.max_rows', limitRows)\n",
    "    display(df.limit(limitRows).toPandas())\n",
    "    pandas.reset_option('display.max_rows')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Helper function to have nicer formatting of Spark DataFrames"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating Tables and Loading Tables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"images/dselogo.png\" width=\"400\" height=\"200\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from cassandra.cluster import Cluster\n",
    "from cassandra.auth import PlainTextAuthProvider\n",
    "\n",
    "cloud_config = {\n",
    "    'secure_connect_bundle': '/home/jovyan/secureconnect/secure-connect-colvin-better-botz.zip'\n",
    "}\n",
    "auth_provider = PlainTextAuthProvider(username='james', password='@DSjwc127!')\n",
    "cluster = Cluster(cloud=cloud_config, auth_provider=auth_provider)\n",
    "session = cluster.connect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Demo Keyspace (DELETE THIS SECTION)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "session.execute(\"\"\"\n",
    "    CREATE KEYSPACE IF NOT EXISTS accelerate \n",
    "    WITH REPLICATION = \n",
    "    { 'class' : 'SimpleStrategy', 'replication_factor' : 1 }\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set keyspace "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "session.set_keyspace('betterbotz')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create table called `movies`. Our PRIMARY will be a unique key (movieid) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<cassandra.cluster.ResultSet at 0x7f5caa200950>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query = \"CREATE TABLE IF NOT EXISTS movies \\\n",
    "                                   (movieid int, title text, genres text, \\\n",
    "                                   PRIMARY KEY (movieid))\"\n",
    "session.execute(query)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create table called `movieRatings`. Our PRIMARY key will be a compositite key (userid, movieid)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<cassandra.cluster.ResultSet at 0x7f5caa202bd0>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query = \"CREATE TABLE IF NOT EXISTS movieratings \\\n",
    "                                   (userid int, movieid int, rating float, timestamp text, \\\n",
    "                                   PRIMARY KEY (userid, movieid))\"\n",
    "session.execute(query)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Movies\n",
    "\n",
    "* **Movieid**\n",
    "* **Title**\n",
    "* **Genres**\n",
    "\n",
    "## Movie Ratings Table\n",
    "### What do these of these 4 columns represent:\n",
    "\n",
    "* **UserId**\n",
    "* **MovieId**\n",
    "* **Rating**\n",
    "* **Timestamp**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load 2 Movie Dataset -- Movies and Movie Ratings Table\n",
    "<img src=\"images/bttf3.jpg\" width=\"500\" height=\"300\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Movie datasets from CSV file (rating_movies.csv, movies.csv)\n",
    "* No clean up was requried! How nice :)\n",
    "\n",
    "#### Insert all the Movie Data into the table `movies` and `movieratings`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-b28209188854>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0mquery\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"INSERT INTO movieratings (userid, movieid, rating, timestamp)\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0mquery\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mquery\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\" VALUES (%s, %s, %s, %s)\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m     \u001b[0msession\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mquery\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrow\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrow\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrow\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrow\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/cassandra/cluster.cpython-37m-x86_64-linux-gnu.so\u001b[0m in \u001b[0;36mcassandra.cluster.Session.execute\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/cassandra/cluster.cpython-37m-x86_64-linux-gnu.so\u001b[0m in \u001b[0;36mcassandra.cluster.ResponseFuture.result\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/threading.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    550\u001b[0m             \u001b[0msignaled\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_flag\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    551\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0msignaled\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 552\u001b[0;31m                 \u001b[0msignaled\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_cond\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    553\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0msignaled\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    554\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/threading.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    294\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m    \u001b[0;31m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    295\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 296\u001b[0;31m                 \u001b[0mwaiter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    297\u001b[0m                 \u001b[0mgotit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    298\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "fileName = 'data/ratings.csv'\n",
    "input_file = open(fileName, 'r')\n",
    "\n",
    "for line in input_file:\n",
    "    row = line.split(',')\n",
    "    \n",
    "    query = \"INSERT INTO movieratings (userid, movieid, rating, timestamp)\"\n",
    "    query = query + \" VALUES (%s, %s, %s, %s)\"\n",
    "    session.execute(query, (int(row[0]), int(row[1]), float(row[2]), row[3]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fileName = 'data/movies.csv'\n",
    "input_file = open(fileName, 'r')\n",
    "\n",
    "for line in input_file:\n",
    "    row = line.split(',')\n",
    "        \n",
    "    query = \"INSERT INTO movies (movieid, title, genres)\"\n",
    "    query = query + \" VALUES (%s, %s, %s)\"\n",
    "    session.execute(query, (int(row[0]), row[1], row[2]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Machine Learning with Apache Spark\n",
    "<img src=\"images/sparklogo.png\" width=\"150\" height=\"200\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create a spark session that is connected to cassandra. From there load each table into a Spark Dataframe and take a count of the number of rows in each."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = SparkSession \\\n",
    "    .builder \\\n",
    "    .appName('demo') \\\n",
    "    .master(\"local\") \\\n",
    "    .config( \\\n",
    "        \"spark.cassandra.connection.config.cloud.path\", \\\n",
    "        \"file:/home/jovyan/secureconnect/secure-connect-colvin-better-botz.zip\") \\\n",
    "    .config(\"spark.cassandra.auth.username\", \"james\") \\\n",
    "    .config(\"spark.cassandra.auth.password\", \"@DSjwc127!\") \\\n",
    "    .getOrCreate()\n",
    "\n",
    "movieDF = spark.read.format(\"org.apache.spark.sql.cassandra\").options(table=\"movieratings\", keyspace=\"betterbotz\").load()\n",
    "\n",
    "print (\"Table Row Count: \")\n",
    "print (movieDF.count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "showDF(movieDF)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## This dataset is not in the format we need it to be. We need it to be more in a transaction format. Each user and the list of movies they have reviewed. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Remove the timestamp column since we will not be using that"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "newMovieDF = movieDF.drop('timestamp')\n",
    "showDF(newMovieDF)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Before we collect the set of movies for each user let's filter out any movies they rated below 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "newestMovies = newMovieDF.filter(\"rating > 3\")\n",
    "showDF(newestMovies)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### GroupBy the user id and create a collection set of all the movies they have rated and seen. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "group_user = newestMovies.groupBy('userid').agg(collect_set('movieid').alias('moviesRated'))\n",
    "group_user.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### For FP-Growth the list needs to be a column named `items`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = group_user.withColumnRenamed(\"moviesRated\", \"items\")\n",
    "showDF(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.select('userid').distinct().count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### FPGROWTH for  Recommendations\n",
    "#### Use Apache Spark MLlib with FPGrowth to find Recommendation \n",
    "#### https://spark.apache.org/docs/latest/ml-frequent-pattern-mining.html\n",
    "#### https://spark.apache.org/docs/latest/api/python/pyspark.ml.html#pyspark.ml.fpm.FPGrowth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fpGrowth = FPGrowth(itemsCol=\"items\", minSupport=0.1, minConfidence=0.2)\n",
    "model = fpGrowth.fit(df)\n",
    "recommendDF=model.transform(df)\n",
    "recommendDF.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### If you have watched these movies `antecedent` then you will like this movie `consquent`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display frequent itemsets.\n",
    "#model.freqItemsets.show()\n",
    "\n",
    "# Display generated association rules.\n",
    "dfAssociation = model.associationRules\n",
    "\n",
    "dfAssociation.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"If you like these movies: \")\n",
    "print(list(dfAssociation.select('antecedent').first()))\n",
    "print(\"Then you will like this movie:\")\n",
    "print(list(dfAssociation.select('consequent').first()))\n",
    "\n",
    "movieYoulike = list(dfAssociation.select('antecedent').first())\n",
    "movieToRecommend=list(dfAssociation.select('consequent').first())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Query database to get movie titles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"select title from movies WHERE movieid=\"\n",
    "query = query + str(movieYoulike[0][0])\n",
    "\n",
    "rows = session.execute(query)\n",
    "print(rows)\n",
    "\n",
    "for user_row in rows:\n",
    "    print (user_row.title)\n",
    "\n",
    "query = \"select title from movies WHERE movieid=\"\n",
    "query = query + str(movieYoulike[0][1])\n",
    "\n",
    "rows = session.execute(query)\n",
    "print(rows)\n",
    "\n",
    "for user_row in rows:\n",
    "    print (user_row.title)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Then you will like this movie ... "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"select title from movies WHERE movieid=\"\n",
    "query = query + str(movieToRecommend[0][0])\n",
    "\n",
    "rows = session.execute(query)\n",
    "print(rows)\n",
    "\n",
    "for user_row in rows:\n",
    "    print (user_row.title)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "session.execute(\"\"\"drop table movies\"\"\")\n",
    "session.execute(\"\"\"drop table movieratings\"\"\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
